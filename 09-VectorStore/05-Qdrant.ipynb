{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qdrant\n",
    "\n",
    "- Author: [HyeonJong Moon](https://github.com/hj0302)\n",
    "- Design: \n",
    "- Peer Review: \n",
    "- This is a part of [LangChain Open Tutorial](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial)\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-4/sub-graph.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58239937-lesson-2-sub-graphs)\n",
    "\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook demonstrates how to utilize the features related to the `Qdrant` vector database.\n",
    "\n",
    "[`Qdrant`](https://python.langchain.com/docs/integrations/vectorstores/qdrant/) is an open-source vector similarity search engine designed to store, search, and manage high-dimensional vectors with additional payloads. It offers a production-ready service with a user-friendly API, suitable for applications such as semantic search, recommendation systems, and more.\n",
    "\n",
    "Qdrant's architecture is optimized for efficient vector similarity searches, employing advanced indexing techniques like Hierarchical Navigable Small World (HNSW) graphs to enable fast and scalable retrieval of relevant data.\n",
    "\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "- [Overview](#overview)\n",
    "- [Environment Setup](#environment-setup)\n",
    "- [Credentials](#credentials)\n",
    "- [Installation](#installation)\n",
    "- [Initialization](#initialization)\n",
    "- [Manage VectorStore](#manage-vectorstore)\n",
    "- [Query VectorStore](#query-vectorstore)\n",
    "\n",
    "### References\n",
    "\n",
    "- [LangChain Qdrant Reference](https://python.langchain.com/docs/integrations/vectorstores/qdrant/)\n",
    "- [Qdrant Official Reference](https://qdrant.tech/documentation/frameworks/langchain/)\n",
    "- [Qdrant Install Reference](https://qdrant.tech/documentation/guides/installation/)\n",
    "- [Qdrant Cloud Reference](https://cloud.qdrant.io)\n",
    "- [Qdrant Cloud Quickstart Reference](https://qdrant.tech/documentation/quickstart-cloud/)\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Set up the environment. You may refer to Environment Setup for more details.\n",
    "\n",
    "[Note]\n",
    "- `langchain-opentutorial` is a package that provides a set of easy-to-use environment setup, useful functions and utilities for tutorials.\n",
    "- You can checkout the [`langchain-opentutorial`](https://github.com/LangChain-OpenTutorial/langchain-opentutorial-pypi) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install langchain-opentutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "from langchain_opentutorial import package\n",
    "\n",
    "package.install(\n",
    "    [\n",
    "        \"langsmith\",\n",
    "        \"langchain_openai\",\n",
    "        \"langchain_qdrant\",\n",
    "        \"qdrant_client\",\n",
    "        \"langchain_core\",\n",
    "        \"fastembed\",\n",
    "    ],\n",
    "    verbose=False,\n",
    "    upgrade=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables have been set successfully.\n"
     ]
    }
   ],
   "source": [
    "# Set environment variables\n",
    "from langchain_opentutorial import set_env\n",
    "\n",
    "set_env(\n",
    "    {\n",
    "        \"OPEN_API_KEY\": \"\",\n",
    "        \"QDRANT_API_KEY\": \"\",\n",
    "        \"QDRANT_URL\": \"\",\n",
    "        \"LANGCHAIN_API_KEY\": \"\",\n",
    "        \"LANGCHAIN_TRACING_V2\": \"true\",\n",
    "        \"LANGCHAIN_ENDPOINT\": \"https://api.smith.langchain.com\",\n",
    "        \"LANGCHAIN_PROJECT\": \"Qdrant\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can alternatively set API keys such as `OPENAI_API_KEY` in a `.env` file and load them.\n",
    "\n",
    "**[Note]** If you are using a `.env` file, proceed as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credentials\n",
    "\n",
    "Create a new account or sign in to your existing one, and generate an API key for use in this notebook.\n",
    "\n",
    "1. **Log in to Qdrant Cloud** : Go to the [Qdrant Cloud](https://cloud.qdrant.io) website and log in using your email, Google account, or GitHub account.\n",
    "\n",
    "2. **Create a Cluster** : After logging in, navigate to the `\"Clusters\"` section and click the `\"Create\"` button. Choose your desired configurations and region, then click `\"Create\"` to start building your cluster. Once the cluster is created, an API key will be generated for you.\n",
    "\n",
    "3. **Retrieve and Store Your API Key** : When your cluster is created, you will receive an API key. Ensure you save this key in a secure location, as you will need it later. If you lose it, you will have to generate a new one.\n",
    "\n",
    "4. **Manage API Keys** : To create additional API keys or manage existing ones, go to the `\"Access Management\"` section in the Qdrant Cloud dashboard and select `\"Qdrant Cloud API Keys\"` Here, you can create new keys or delete existing ones.\n",
    "\n",
    "```\n",
    "QDRANT_API_KEY=\"YOUR_QDRANT_API_KEY\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "There are several main options for initializing and using the Qdrant vector store:\n",
    "\n",
    "- **Local Mode** : This mode doesn't require a separate server.\n",
    "    - **In-memory storage** (data is not persisted)\n",
    "    - **On-disk storage** (data is saved to your local machine)\n",
    "- **Docker Deployments** : You can run Qdrant using Docker.\n",
    "- **Qdrant Cloud** : Use Qdrant as a managed cloud service.\n",
    "\n",
    "For detailed instructions, see the [installation instructions](https://qdrant.tech/documentation/guides/installation/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In-Memory\n",
    "\n",
    "For simple tests or quick experiments, you might choose to store data directly in memory. This means the data is automatically removed when your client terminates, typically at the end of your script or notebook session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_qdrant import QdrantVectorStore\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# Step 1: Initialize embeddings\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "# Step 2: Initialize Qdrant client\n",
    "client = QdrantClient(\":memory:\")\n",
    "\n",
    "# Step 3: Create a Qdrant collection\n",
    "collection_name = \"demo_collection\"\n",
    "client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=VectorParams(size=3072, distance=Distance.COSINE),\n",
    ")\n",
    "\n",
    "# Step 4: Initialize QdrantVectorStore\n",
    "vector_store = QdrantVectorStore(\n",
    "    client=client,\n",
    "    collection_name=collection_name,\n",
    "    embedding=embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On-Disk Storage\n",
    "\n",
    "With on-disk storage, you can store your vectors directly on your hard drive without requiring a Qdrant server. This ensures that your data persists even when you restart the program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_qdrant import QdrantVectorStore\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# Step 1: Initialize embeddings\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "# Step 2: Initialize Qdrant client\n",
    "qdrant_path = \"./qdrant_memory\"\n",
    "client = QdrantClient(path=qdrant_path)\n",
    "\n",
    "# Step 3: Create a Qdrant collection\n",
    "collection_name = \"demo_collection\"\n",
    "client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=VectorParams(size=3072, distance=Distance.COSINE),\n",
    ")\n",
    "\n",
    "# Step 4: Initialize QdrantVectorStore\n",
    "vector_store = QdrantVectorStore(\n",
    "    client=client,\n",
    "    collection_name=collection_name,\n",
    "    embedding=embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Docker Deployments\n",
    "\n",
    "You can deploy `Qdrant` in a production environment using [Docker](https://qdrant.tech/documentation/guides/installation/#docker) and [Docker Compose](https://qdrant.tech/documentation/guides/installation/#docker-compose). Refer to the Docker and Docker Compose setup instructions in the development section for detailed information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_qdrant import QdrantVectorStore\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# Step 1: Initialize embeddings\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "# Step 2: Initialize Qdrant client\n",
    "url = \"http://localhost:6333\"\n",
    "client = QdrantClient(url=url)\n",
    "\n",
    "# Step 3: Create a Qdrant collection\n",
    "collection_name = \"demo_collection\"\n",
    "client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=VectorParams(size=3072, distance=Distance.COSINE),\n",
    ")\n",
    "\n",
    "# Step 4: Initialize QdrantVectorStore\n",
    "vector_store = QdrantVectorStore(\n",
    "    client=client,\n",
    "    collection_name=collection_name,\n",
    "    embedding=embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qdrant Cloud\n",
    "\n",
    "For a production environment, you can use [Qdrant Cloud](https://cloud.qdrant.io/). It offers fully managed `Qdrant` databases with features such as horizontal and vertical scaling, one-click setup and upgrades, monitoring, logging, backups, and disaster recovery. For more information, refer to the [Qdrant Cloud documentation](https://qdrant.tech/documentation/cloud/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "# Fetch the Qdrant server URL from environment variables or prompt for input\n",
    "if not os.getenv(\"QDRANT_URL\"):\n",
    "    os.environ[\"QDRANT_URL\"] = getpass.getpass(\"Enter your Qdrant Cloud URL key: \")\n",
    "url = os.environ.get(\"QDRANT_URL\")\n",
    "\n",
    "# Fetch the Qdrant API key from environment variables or prompt for input\n",
    "if not os.getenv(\"QDRANT_API_KEY\"):\n",
    "    os.environ[\"QDRANT_API_KEY\"] = getpass.getpass(\"Enter your Qdrant API key: \")\n",
    "api_key = os.environ.get(\"QDRANT_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_qdrant import QdrantVectorStore\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# Step 1: Initialize embeddings\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "# Step 2: Initialize Qdrant client\n",
    "client = QdrantClient(\n",
    "    url=url,\n",
    "    api_key=api_key,\n",
    ")\n",
    "\n",
    "# Step 3: Create a Qdrant collection\n",
    "collection_name = \"demo_collection\"\n",
    "client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=VectorParams(size=3072, distance=Distance.COSINE),\n",
    ")\n",
    "\n",
    "# Step 4: Initialize QdrantVectorStore\n",
    "vector_store = QdrantVectorStore(\n",
    "    client=client,\n",
    "    collection_name=collection_name,\n",
    "    embedding=embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "\n",
    "Once you've established your vector store, you'll likely need to manage the collections within it. Here are some common operations you can perform:\n",
    "\n",
    "- Create a collection\n",
    "- List collections\n",
    "- Delete a collection\n",
    "- Use an existing collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Collection\n",
    "\n",
    "To create a new collection in your Qdrant instance, you can use the `QdrantClient` class from the `qdrant-client` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection 'my_new_collection' created successfully.\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import VectorParams, Distance\n",
    "\n",
    "# Step 1: Define collection name\n",
    "collection_name = \"my_new_collection\"\n",
    "\n",
    "# Initialize the Qdrant client\n",
    "client = QdrantClient(\n",
    "    url=url,\n",
    "    api_key=api_key,\n",
    ")\n",
    "\n",
    "# Create a new collection in Qdrant\n",
    "client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=VectorParams(size=3072, distance=Distance.COSINE),\n",
    ")\n",
    "\n",
    "# Print confirmation\n",
    "print(f\"Collection '{collection_name}' created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List Collections\n",
    "\n",
    "To list all existing collections in your Qdrant instance, you can use the `QdrantClient` class from the `qdrant-client` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection Name: my_new_collection\n",
      "Collection Name: demo_collection\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "\n",
    "# Initialize the Qdrant client\n",
    "client = QdrantClient(\n",
    "    url=url,\n",
    "    api_key=api_key,\n",
    ")\n",
    "\n",
    "# Retrieve and print collection names\n",
    "collections_response = client.get_collections()\n",
    "for collection in collections_response.collections:\n",
    "    print(f\"Collection Name: {collection.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete a Collection\n",
    "\n",
    "To delete a collection in Qdrant using the Python client, you can use the `delete_collection` method of the `QdrantClient` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection 'my_new_collection' has been deleted.\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "\n",
    "# Define collection name\n",
    "collection_name = \"my_new_collection\"\n",
    "\n",
    "# Initialize the Qdrant client\n",
    "client = QdrantClient(\n",
    "    url=url,\n",
    "    api_key=api_key,\n",
    ")\n",
    "\n",
    "# Delete the collection\n",
    "if client.delete_collection(collection_name=collection_name):\n",
    "    print(f\"Collection '{collection_name}' has been deleted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use an Existing Collection\n",
    "\n",
    "This code snippet demonstrates how to initialize a `QdrantVectorStore` using the `from_existing_collection` method provided by the langchain_qdrant library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_qdrant import QdrantVectorStore\n",
    "\n",
    "collection_name = \"demo_collection\"\n",
    "\n",
    "# Initialize QdrantVectorStore using from_existing_collection method\n",
    "vector_store = QdrantVectorStore.from_existing_collection(\n",
    "    embedding=embeddings,\n",
    "    collection_name=collection_name,\n",
    "    url=url,\n",
    "    api_key=api_key,\n",
    "    prefer_grpc=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Direct Initialization** \n",
    "- Offers more control by utilizing an existing `QdrantClient` instance, making it suitable for complex applications that require customized client configurations.\n",
    "\n",
    "**from_existing_collection Method** \n",
    "- Provides a simplified and concise way to connect to an existing collection, ideal for quick setups or simpler applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manage VectorStore\n",
    "\n",
    "After you've created your vector store, you can interact with it by adding or deleting items. Here are some common operations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Items to the Vector Store\n",
    "\n",
    "With `Qdrant`, you can add items to your vector store using the `add_documents` function. If you add a document with an ID that already exists, the existing document will be updated with the new data. This process is called `upsert`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 222 documents to Qdrant collection 'little_prince_collection'\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import TextLoader\n",
    "from uuid import uuid4\n",
    "\n",
    "# Load the text file\n",
    "loader = TextLoader(\"./data/the_little_prince.txt\")\n",
    "documents = loader.load()\n",
    "\n",
    "# Initialize the text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=600, chunk_overlap=100, length_function=len\n",
    ")\n",
    "split_docs = text_splitter.split_documents(documents)\n",
    "\n",
    "# Generate unique IDs for documents\n",
    "uuids = [str(uuid4()) for _ in split_docs]\n",
    "\n",
    "# Add documents to the vector store\n",
    "vector_store.add_documents(\n",
    "    documents=split_docs,\n",
    "    ids=uuids,\n",
    "    batch_size=10,\n",
    ")\n",
    "print(\n",
    "    f\"Uploaded {len(split_docs)} documents to Qdrant collection 'little_prince_collection'\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete Items from the Vector Store\n",
    "\n",
    "To remove items from your vector store, use the `delete` function. You can specify the items to delete using either IDs or filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector point with ID c824af22-779a-4294-8c7b-6bc9de1ee9ce has been deleted.\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the last point ID from the list of UUIDs\n",
    "point_id = uuids[-1]\n",
    "\n",
    "# Delete the vector point by its point_id\n",
    "vector_store.delete(ids=[point_id])\n",
    "\n",
    "# Print confirmation of deletion\n",
    "print(f\"Vector point with ID {point_id} has been deleted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update items from vector store\n",
    "\n",
    "To update items in your vector store, use the `set_payload` function. This function allows you to modify the content or metadata of existing item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_point_payload(vector_store, point_id):\n",
    "    \"\"\"\n",
    "    Retrieve the payload of a point from the Qdrant collection using its ID.\n",
    "\n",
    "    Args:\n",
    "        vector_store (QdrantVectorStore): The vector store instance connected to the Qdrant collection.\n",
    "        point_id (str): The unique identifier of the point to retrieve.\n",
    "\n",
    "    Returns:\n",
    "        dict: The payload of the retrieved point.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the point with the specified ID is not found in the collection.\n",
    "    \"\"\"\n",
    "    # Retrieve the vector point using the client\n",
    "    response = vector_store.client.retrieve(\n",
    "        collection_name=vector_store.collection_name,\n",
    "        ids=[point_id],\n",
    "    )\n",
    "\n",
    "    # Check if the response is empty\n",
    "    if not response:\n",
    "        raise ValueError(f\"Point ID {point_id} not found in the collection.\")\n",
    "\n",
    "    # Extract the payload from the retrieved point\n",
    "    point = response[0]\n",
    "    payload = point.payload\n",
    "    print(f\"Payload for point ID {point_id}: \\n{payload}\\n\")\n",
    "\n",
    "    return payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Payload for point ID 13d90d2d-2988-4c33-9b55-8449c8525200: \n",
      "{'page_content': 'The Little Prince\\nWritten By Antoine de Saiot-Exupery (1900〜1944)', 'metadata': {'source': './data/the_little_prince.txt'}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "point_id = uuids[0]\n",
    "\n",
    "# Retrieve the payload for the specified point ID\n",
    "payload = retrieve_point_payload(vector_store, point_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_point_payload(vector_store, point_id, new_payload):\n",
    "    \"\"\"\n",
    "    Update the payload of a specific point in a Qdrant collection.\n",
    "\n",
    "    Args:\n",
    "        vector_store (QdrantVectorStore): The vector store instance connected to the Qdrant collection.\n",
    "        point_id (str): The unique identifier of the point to update.\n",
    "        new_payload (dict): A dictionary containing the new payload data to set for the point.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "\n",
    "    Raises:\n",
    "        Exception: If the update operation fails.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Update the payload for the specified point\n",
    "        vector_store.client.set_payload(\n",
    "            collection_name=vector_store.collection_name,\n",
    "            payload=new_payload,\n",
    "            points=[point_id],\n",
    "        )\n",
    "        print(f\"Successfully updated payload for point ID {point_id}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to update payload for point ID {point_id}: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully updated payload for point ID 13d90d2d-2988-4c33-9b55-8449c8525200.\n"
     ]
    }
   ],
   "source": [
    "point_id = uuids[0]\n",
    "new_payload = {\"page_content\": \"The Little Prince (1943)\"}\n",
    "\n",
    "# Update the point's payload\n",
    "update_point_payload(vector_store, point_id, new_payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upsert items to vector store (parallel)\n",
    "\n",
    "Use the `set_payload` function in parallel to efficiently add or update multiple items in the vector store using unique IDs, data, and metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "\n",
    "def update_payloads_parallel(\n",
    "    vector_store, updates: List[Tuple[str, Dict]], num_workers: int\n",
    "):\n",
    "    \"\"\"\n",
    "    Update the payloads of multiple points in a Qdrant collection in parallel.\n",
    "\n",
    "    Args:\n",
    "        updates (List[Tuple[str, Dict]]): A list of tuples containing point IDs and their corresponding new payloads.\n",
    "        num_workers (int): Number of worker threads to use for parallel execution.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Create a ThreadPoolExecutor\n",
    "    with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "        # Submit update tasks to the executor\n",
    "        future_to_point_id = {\n",
    "            executor.submit(\n",
    "                update_point_payload, vector_store, point_id, new_payload\n",
    "            ): point_id\n",
    "            for point_id, new_payload in updates\n",
    "        }\n",
    "\n",
    "        # Process completed futures\n",
    "        for future in as_completed(future_to_point_id):\n",
    "            point_id = future_to_point_id[future]\n",
    "            try:\n",
    "                future.result()\n",
    "            except Exception as e:\n",
    "                print(f\"Error updating point ID {point_id}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Payload for point ID c0c2356a-5010-4bd6-aaee-990d0ab6fb48: \n",
      "{'page_content': 'Born in 1900 in Lyons, France, young Antoine was filled with a passion for adventure. When he failed an entrance exam for the Naval Academy, his interest in aviation took hold. He joined the French Army Air Force in 1921 where he first learned to fly a plane. Five years later, he would leave the military in order to begin flying air mail between remote settlements in the Sahara desert.', 'metadata': {'source': './data/the_little_prince.txt'}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "payload = retrieve_point_payload(vector_store, uuids[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully updated payload for point ID e72f942f-8f24-4855-b99e-41fa11e467fc.\n",
      "Successfully updated payload for point ID c0c2356a-5010-4bd6-aaee-990d0ab6fb48.\n"
     ]
    }
   ],
   "source": [
    "# Update example\n",
    "updates = [\n",
    "    (\n",
    "        uuids[1],\n",
    "        {\n",
    "            \"page_content\": \"Antoine de Saint-Exupéry's passion for aviation not only fueled remarkable stories but also reflected the enduring allure of flight, inspiring technological advancements and daring feats that captivated the world over the past century.\"\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        uuids[2],\n",
    "        {\n",
    "            \"page_content\": \"Antoine de Saint-Exupéry, born in 1900 in Lyons, France, had an adventurous spirit from a young age. After failing the Naval Academy entrance exam, his fascination with aviation began to take flight. In 1921, he joined the French Army Air Force and learned to pilot an aircraft. By 1926, he left the military to embark on a career as an airmail pilot, delivering letters to isolated communities in the vast Sahara desert\"\n",
    "        },\n",
    "    ),\n",
    "    # Add more (point_id, new_payload) tuples as needed\n",
    "]\n",
    "\n",
    "# Update payloads in parallel\n",
    "num_workers = 4\n",
    "update_payloads_parallel(vector_store, updates, num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query VectorStore\n",
    "\n",
    "Once your vector store has been created and the relevant documents have been added you will most likely wish to query it during the running of your chain or agent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query directly\n",
    "\n",
    "The most straightforward use case for the `Qdrant` vector store is performing similarity searches. Internally, your query is converted into a vector embedding, which is then used to identify similar documents within the `Qdrant` collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* \"Go and look again at the roses. You will understand now that yours is unique in all the world. Then come back to say goodbye to me, and I will make you a present of a secret.\" \n",
      "The little prince went\n",
      " [{'source': './data/the_little_prince.txt', '_id': '634892c2-9fc9-4bb5-9310-531149d1ade1', '_collection_name': 'demo_collection'}]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the significance of the rose in The Little Prince?\"\n",
    "\n",
    "# Perform similarity search in the vector store\n",
    "results = vector_store.similarity_search(\n",
    "    query=query,\n",
    "    k=1,\n",
    ")\n",
    "\n",
    "for res in results:\n",
    "    print(f\"* {res.page_content[:200]}\\n [{res.metadata}]\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity search with score\n",
    "\n",
    "You can also search with score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* [SIM=0.584994] \"Go and look again at the roses. You will understand now that yours is unique in all the world. Then come back to say goodbye to me, and I will make you a present of a secret.\" \n",
      "The little prince went\n",
      " [{'source': './data/the_little_prince.txt', '_id': '634892c2-9fc9-4bb5-9310-531149d1ade1', '_collection_name': 'demo_collection'}]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the significance of the rose in The Little Prince?\"\n",
    "\n",
    "results = vector_store.similarity_search_with_score(\n",
    "    query=query,\n",
    "    k=1,\n",
    ")\n",
    "for doc, score in results:\n",
    "    print(f\"* [SIM={score:3f}] {doc.page_content[:200]}\\n [{doc.metadata}]\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query by turning into retreiver\n",
    "\n",
    "You can also transform the vector store into a `retriever` for easier usage in your workflows or chains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* \"Go and look again at the roses. You will understand now that yours is unique in all the world. Then come back to say goodbye to me, and I will make you a present of a secret.\" \n",
      "The little prince went\n",
      " [{'source': './data/the_little_prince.txt', '_id': '634892c2-9fc9-4bb5-9310-531149d1ade1', '_collection_name': 'demo_collection'}]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the significance of the rose in The Little Prince?\"\n",
    "\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    search_kwargs={\"k\": 1, \"score_threshold\": 0.5},\n",
    ")\n",
    "\n",
    "results = retriever.invoke(query)\n",
    "\n",
    "for res in results:\n",
    "    print(f\"* {res.page_content[:200]}\\n [{res.metadata}]\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search with Filtering\n",
    "\n",
    "This code demonstrates how to search for and retrieve records from a Qdrant vector database based on specific metadata field values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client.http.models import Filter, FieldCondition, MatchValue, MatchText\n",
    "\n",
    "\n",
    "def filter_and_retrieve_records(vector_store, filter_condition):\n",
    "    \"\"\"\n",
    "    Retrieve records from a Qdrant vector store based on a given filter condition.\n",
    "\n",
    "    Args:\n",
    "        vector_store (QdrantVectorStore): The vector store instance connected to the Qdrant collection.\n",
    "        filter_condition (Filter): The filter condition to apply for retrieving records.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of records matching the filter condition.\n",
    "    \"\"\"\n",
    "    all_records = []\n",
    "    next_page_offset = None\n",
    "\n",
    "    while True:\n",
    "        response, next_page_offset = vector_store.client.scroll(\n",
    "            collection_name=vector_store.collection_name,\n",
    "            scroll_filter=filter_condition,\n",
    "            limit=10,\n",
    "            offset=next_page_offset,\n",
    "            with_payload=True,\n",
    "        )\n",
    "        all_records.extend(response)\n",
    "        if next_page_offset is None:\n",
    "            break\n",
    "\n",
    "    return all_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: c0c2356a-5010-4bd6-aaee-990d0ab6fb48\n",
      "Payload: {'page_content': 'Antoine de Saint-Exupéry, born in 1900 in Lyons, France, had an adventurous spirit from a young age. After failing the Naval Academy entrance exam, his fascination with aviation began to take flight. In 1921, he joined the French Army Air Force and learned to pilot an aircraft. By 1926, he left the military to embark on a career as an airmail pilot, delivering letters to isolated communities in the vast Sahara desert', 'metadata': {'source': './data/the_little_prince.txt'}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filter_condition = Filter(\n",
    "    must=[\n",
    "        FieldCondition(\n",
    "            key=\"page_content\",  # Ensure this key matches your payload structure\n",
    "            match=MatchText(text=\"Academy\"),  # Use MatchValue for exact matches\n",
    "            # key=\"metadata.source\",\n",
    "            # match=MatchValue(value=\"./data/the_little_prince.txt\")\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Retrieve records based on the filter condition\n",
    "records = filter_and_retrieve_records(vector_store, filter_condition)\n",
    "\n",
    "# Print the retrieved records\n",
    "for record in records[:1]:\n",
    "    print(f\"ID: {record.id}\\nPayload: {record.payload}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete with Filtering\n",
    "\n",
    "This code demonstrates how to delete records from a Qdrant vector database based on specific metadata field values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delete operation completed.\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client.http.models import Filter, FieldCondition, MatchValue\n",
    "\n",
    "# Define the filter condition\n",
    "filter_condition = Filter(\n",
    "    must=[\n",
    "        FieldCondition(\n",
    "            key=\"page_content\",  # Ensure this key matches your payload structure\n",
    "            match=MatchText(text=\"Academy\"),  # Use MatchValue for exact matches\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Perform the delete operation\n",
    "client.delete(\n",
    "    collection_name=vector_store.collection_name,\n",
    "    points_selector=filter_condition,\n",
    "    wait=True,\n",
    ")\n",
    "\n",
    "print(\"Delete operation completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering and Updating Records\n",
    "\n",
    "This code demonstrates how to retrieve and display records from a Qdrant collection based on a specific metadata field value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully updated payload for point ID 071cae6b-5dc8-40ab-aac2-aff8796bff7f.\n",
      "Successfully updated payload for point ID 09628d96-3ec1-4914-b849-1e90dbe4dbc0.\n",
      "Successfully updated payload for point ID 0fe36061-9a47-4499-a5b5-bba74d7370a5.\n",
      "Successfully updated payload for point ID 12325628-09db-4526-8429-31b99c04e0ec.\n",
      "Successfully updated payload for point ID 19533ec1-ea7b-4e83-9a37-a71c3bc489f2.\n",
      "Successfully updated payload for point ID 2416e48f-8520-4d2e-9492-c7f0ae19fbd8.\n",
      "Successfully updated payload for point ID 29dd8cd9-5450-4ab3-8c39-e8eb56e7fee8.\n",
      "Successfully updated payload for point ID 325dd5af-0fc4-42f6-ad55-bb498c496b2a.\n",
      "Successfully updated payload for point ID 32dd484e-6413-4074-81d0-7233337469ef.\n",
      "Successfully updated payload for point ID 48f42368-c969-4fcb-91d3-770cd966294f.\n",
      "Successfully updated payload for point ID 48fd93c4-3e61-4e77-af86-d633535db061.\n",
      "Successfully updated payload for point ID 591594ef-76ab-4aca-803b-0dfe09ffd0e4.\n",
      "Successfully updated payload for point ID 5a0504c6-56f4-4667-8c98-2f31f136640a.\n",
      "Successfully updated payload for point ID 7a7ed2a6-b3b4-4d8a-9dd7-6687602b5b68.\n",
      "Successfully updated payload for point ID 7ed0d4c8-42be-4afb-9dc2-ab33d7d5f62e.\n",
      "Successfully updated payload for point ID 8efd04f0-3abc-4e10-92b5-d577451a135d.\n",
      "Successfully updated payload for point ID a3b96045-6c99-4541-b8f6-4cc291e35581.\n",
      "Successfully updated payload for point ID a64f34f6-b44b-4694-b357-cdec17ecd644.\n",
      "Successfully updated payload for point ID aa0519a6-80de-4e20-9757-811dc4fbaca7.\n",
      "Successfully updated payload for point ID c5a26ed3-4d5d-4325-b193-7fed809d2665.\n",
      "Successfully updated payload for point ID cb314628-bb64-4472-8cc8-ebacfab47262.\n",
      "Successfully updated payload for point ID d6bb59e4-9a20-4e6e-8591-235600b5165b.\n",
      "Successfully updated payload for point ID e46ed917-dc43-431e-aa1e-f1d28e25ff25.\n",
      "Successfully updated payload for point ID eda5363f-bb0a-4259-9c60-9bc50e46fc2a.\n",
      "Successfully updated payload for point ID fa6e2b4f-f698-4773-81fa-557b4073464d.\n",
      "Successfully updated payload for point ID fd58693b-fc06-40a0-aab8-638c6dfe9f2f.\n",
      "Successfully updated payload for point ID ffeb408c-ef72-4963-b5d3-d7035c788566.\n",
      "Update operation completed.\n"
     ]
    }
   ],
   "source": [
    "# Define the filter condition\n",
    "filter_condition = Filter(\n",
    "    must=[\n",
    "        FieldCondition(\n",
    "            key=\"page_content\",  # Ensure this key matches your payload structure\n",
    "            match=MatchText(text=\"Chapter\"),  # Use MatchValue for exact matches\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "# Retrieve matching records using the existing function\n",
    "matching_points = filter_and_retrieve_records(vector_store, filter_condition)\n",
    "\n",
    "# Prepare updates for matching points\n",
    "for point in matching_points:\n",
    "    updated_payload = point.payload.copy()\n",
    "\n",
    "    # Update the page_content field by replacing \"Chapter\" with \"Chapter -\"\n",
    "    updated_payload[\"page_content\"] = updated_payload[\"page_content\"].replace(\n",
    "        \"Chapter\", \"Chapter -\"\n",
    "    )\n",
    "\n",
    "    # Update the payload using the existing function\n",
    "    update_point_payload(vector_store, point.id, updated_payload)\n",
    "\n",
    "print(\"Update operation completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity Search Options\n",
    "\n",
    "When using `QdrantVectorStore`, you have three options for performing similarity searches. You can select the desired search mode using the retrieval_mode parameter when you set up the class. The available modes are:\n",
    "\n",
    "- Dense Vector Search (Default)\n",
    "- Sparse Vector Search\n",
    "- Hybrid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense Vector Search\n",
    "\n",
    "To perform a search using only dense vectors:\n",
    "\n",
    "The `retrieval_mode` parameter must be set to `RetrievalMode.DENSE`. This is also the default setting.\n",
    "You need to provide a [dense embeddings](https://python.langchain.com/docs/integrations/text_embedding/) value through the embedding parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* \"Go and look again at the roses. You will understand now that yours is unique in all the world. Then come back to say goodbye to me, and I will make you a present of a secret.\" \n",
      "The little prince went\n",
      " [{'source': './data/the_little_prince.txt', '_id': 'b024fac2-620e-4102-bf55-a53becd3d174', '_collection_name': 'dense_collection'}]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_qdrant import RetrievalMode\n",
    "\n",
    "query = \"What is the significance of the rose in The Little Prince?\"\n",
    "\n",
    "# Initialize QdrantVectorStore\n",
    "vector_store = QdrantVectorStore.from_documents(\n",
    "    documents=split_docs,\n",
    "    embedding=embeddings,\n",
    "    url=url,\n",
    "    api_key=api_key,\n",
    "    collection_name=\"dense_collection\",\n",
    "    retrieval_mode=RetrievalMode.DENSE,\n",
    "    batch_size=10,\n",
    ")\n",
    "\n",
    "# Perform similarity search in the vector store\n",
    "results = vector_store.similarity_search(\n",
    "    query=query,\n",
    "    k=1,\n",
    ")\n",
    "\n",
    "for res in results:\n",
    "    print(f\"* {res.page_content[:200]}\\n [{res.metadata}]\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse Vector Search\n",
    "\n",
    "To search with only sparse vectors,\n",
    "\n",
    "The `retrieval_mode` parameter should be set to `RetrievalMode.SPARSE` .\n",
    "An implementation of the [SparseEmbeddings](https://github.com/langchain-ai/langchain/blob/master/libs/partners/qdrant/langchain_qdrant/sparse_embeddings.py) interface using any sparse embeddings provider has to be provided as value to the `sparse_embedding` parameter.\n",
    "The `langchain-qdrant` package provides a FastEmbed based implementation out of the box.\n",
    "\n",
    "To use it, install the [FastEmbed](https://github.com/qdrant/fastembed) package.\n",
    "\n",
    "pip install fastembed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* [ Chapter 20 ]\n",
      "- the little prince discovers a garden of roses\n",
      "But it happened that after walking for a long time through sand, and rocks, and snow, the little prince at last came upon a road. And all\n",
      " [{'source': './data/the_little_prince.txt', '_id': '9b772687-0981-4e0b-acc6-a13b76746665', '_collection_name': 'sparse_collection'}]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_qdrant import FastEmbedSparse, RetrievalMode\n",
    "\n",
    "sparse_embeddings = FastEmbedSparse(model_name=\"Qdrant/bm25\")\n",
    "\n",
    "query = \"What is the significance of the rose in The Little Prince?\"\n",
    "\n",
    "# Initialize QdrantVectorStore\n",
    "vector_store = QdrantVectorStore.from_documents(\n",
    "    documents=split_docs,\n",
    "    embedding=embeddings,\n",
    "    sparse_embedding=sparse_embeddings,\n",
    "    url=url,\n",
    "    api_key=api_key,\n",
    "    collection_name=\"sparse_collection\",\n",
    "    retrieval_mode=RetrievalMode.SPARSE,\n",
    "    batch_size=10,\n",
    ")\n",
    "\n",
    "# Perform similarity search in the vector store\n",
    "results = vector_store.similarity_search(\n",
    "    query=query,\n",
    "    k=1,\n",
    ")\n",
    "\n",
    "for res in results:\n",
    "    print(f\"* {res.page_content[:200]}\\n [{res.metadata}]\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hybrid Vector Search\n",
    "To perform a hybrid search using dense and sparse vectors with score fusion,\n",
    "\n",
    "- The `retrieval_mode` parameter should be set to `RetrievalMode.HYBRID` .\n",
    "- A [ `dense embeddings` ](https://python.langchain.com/docs/integrations/text_embedding/) value should be provided to the `embedding` parameter.\n",
    "- An implementation of the [ `SparseEmbeddings` ](https://github.com/langchain-ai/langchain/blob/master/libs/partners/qdrant/langchain_qdrant/sparse_embeddings.py) interface using any sparse embeddings provider has to be provided as value to the `sparse_embedding` parameter.\n",
    "\n",
    "Note that if you've added documents with the `HYBRID` mode, you can switch to any retrieval mode when searching. Since both the dense and sparse vectors are available in the collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* [ Chapter 20 ]\n",
      "- the little prince discovers a garden of roses\n",
      "But it happened that after walking for a long time through sand, and rocks, and snow, the little prince at last came upon a road. And all\n",
      " [{'source': './data/the_little_prince.txt', '_id': '6540d214-84f2-4505-b2f1-7aa937f7e2d0', '_collection_name': 'hybrid_collection'}]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_qdrant import FastEmbedSparse, RetrievalMode\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "query = \"What is the significance of the rose in The Little Prince?\"\n",
    "\n",
    "embedding = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "sparse_embeddings = FastEmbedSparse(model_name=\"Qdrant/bm25\")\n",
    "\n",
    "# Initialize QdrantVectorStore\n",
    "vector_store = QdrantVectorStore.from_documents(\n",
    "    documents=split_docs,\n",
    "    embedding=embedding,\n",
    "    sparse_embedding=sparse_embeddings,\n",
    "    url=url,\n",
    "    api_key=api_key,\n",
    "    collection_name=\"hybrid_collection\",\n",
    "    retrieval_mode=RetrievalMode.HYBRID,\n",
    "    batch_size=10,\n",
    ")\n",
    "\n",
    "# Perform similarity search in the vector store\n",
    "results = vector_store.similarity_search(\n",
    "    query=query,\n",
    "    k=1,\n",
    ")\n",
    "\n",
    "for res in results:\n",
    "    print(f\"* {res.page_content[:200]}\\n [{res.metadata}]\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-opentutorial-FZ3yxgZW-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
